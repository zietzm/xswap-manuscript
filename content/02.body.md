## Introduction

### Node degree

![Degree figure](){#fig:degree width="100%"}

### Edge prediction

### Feature-degree correlation


## Methods

### Network permutation

### XSwap algorithm

Hanhijärvi, et al. presented XSwap [@doi:10.1137/1.9781611972795.67], an algorithm for the randomization ("permutation") of unweighted networks (Figure {@fig:algo}A).
The algorithm picks two existing edges at random, and if the edges constitute a valid swap, exchanges the targets between the edges (Figure {@fig:xswap}).

![Graphical representation of the XSwap algorithm applied to two edges.
The algorithm preserves both the source- and target-degree for all nodes.](images/xswap_figure.png){#fig:xswap width="50%"}

To allow greater flexibility, we modified the algorithm by adding two parameters, "`allow_self_loops`", and "`allow_antiparallel`" that allow a greater variety of network types to be permuted (Figure {@fig:algo}B).
Specifically, two chosen edges constitute a valid swap if they preserve degree for all four involved nodes and do not violate the above condition options.
The motivation for these generalizations is to make the permutation method applicable both to directed and undirected graphs, as well as to networks with different types of nodes, variously called multipartite, heterogeneous, or multimodal networks.
We provide documentation for parameter choices depending on the type of network being permuted in the GitHub repository (https://github.com/hetio/xswap).
The original algorithm and our proposed modification are given in Figure {@fig:algo}.

![
  **A.** XSwap algorithm due to Hanhijärvi, et al. [@doi:10.1137/1.9781611972795.67].
  **B.** Proposed modification to XSwap algorithm](images/xswap_algos.png){#fig:algo width="100%"}

### Edge prior

We introduce the "edge prior" to quantify the probability that two nodes are connected based only on their degree.
The edge prior can be estimated using the maximum likelihood estimate for the binomial distribution success probability--the fraction of permuted networks in which a given edge exists.
Based only on permuted networks, the edge prior does not contain any information about the true edges in the (unpermuted) network.
The edge prior is a numerical feature that can be computed for each node pair in a network, and we compared its ability to predict edges in three tasks, discussed below.

### Edge prior approximation

We also considered the possibility that the probability of an edge existing across permuted networks could be written as a closed form equation involving the node pair's degree.
We were unable to find a closed-form solution giving the edge prior without assuming independent node pairs, which we believe is incorrect for XSwap.
Nonetheless, we discovered a good approximation to the edge prior for networks with many nodes and relatively low edge density.

Let $m$ be the total number of edge in the network, and $d(u_i)$, $d(v_j)$ be the source and target degrees of a node pair, respectively.
A good approximation of the edge prior is given by the following:
\begin{equation}
    P_{i,j} = \frac{d(u_i) d(v_j)}{\sqrt{(d(u_i) d(v_j))^2 + (m - d(u_i) - d(v_j) + 1)^2}}
\end{equation}

Further discussion of this approximate edge prior and an derivation are available in [the supplement](#approx-prior-supp).

### Prediction tasks

### Degree-grouping

### Implementation and source code


## Results

### Edge prior

In the first prediction task, we computed three features--the XSwap edge prior, an approximation to the edge prior, and the (scaled) product of source and target node degree--on networks from Hetionet.
We used the features in attempting to reconstruct the 20 networks themselves.
The XSwap-derived edge prior is able to reconstruct many of the networks with a high level of performance, as measured by the AUROC.
Of the 20 individual networks we extracted from Hetionet, 17 had an edge prior self-reconstruction AUROC >= 0.95, with the highest reconstruction AUROC at 0.9971.
Meanwhile, the lowest self-reconstruction performance (AUROC = 0.7697) occurred in the network having the fewest node pairs.

![AUROC of network reconstruction by prediction task.
  The edge prior shows strong performance for network reconstruction when computed on the original (Task 1) and sampled (Task 2) networks.
  The performance reduction from computing features on sampled networks is real but far smaller compared to a new degree distribution.
  ](https://github.com/zietzm/xswap-analysis/raw/862d9504ec8546ea998285a708ab53a6c4f2fe2f/img/auroc_dists.png){#fig:discrimination width="50%"}

The three features used in the comparison are highly rank correlated (median > 0.99999 across metaedges).
Because AUROC takes only rank into account, the three features have very similar AUROC reconstruction performance values for the first, second, and third prediction tasks (max difference < 0.027).
Nonetheless, we found that the edge prior exhibited marginally superior discriminatory performance in 12 of 20 networks.
While the discriminatory abilities are similar, the features are very different in their levels of calibration.
We find that the edge prior is very well calibration for all networks in the first and second tasks, and it shows the best calibration of the three features for each of the prediction tasks (Figure {@fig:calibration}A).
As the edge prior is not based on the networks' true edges, these results indicate that degree sequence alone is highly informative and can allow the reconstruction of edges, and they validate the use of the edge prior for this purpose.

![**A.** Calibration curves for full network reconstruction. 20 networks shown are from Hetionet.
  **B.** Calibration curves for sampled network reconstruction. 20 networks shown are from Hetionet.
  **C.** Boxplots summarizing individual Hetionet network calibrations. Calibration metric is from the two-component decomposition of the Brier score, and a lower score indicates superior calibration.](https://github.com/zietzm/xswap-analysis/raw/fb5e093ab5baedd129629ee8e41526c286cbbe45/img/fig4.calibration.png){#fig:calibration width="100%"}


## Discussion


## Conclusion
